{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bffbceea848b271a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Instalar las siguientes librerias y reiniciar el kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46a78762195e2f8",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow\n",
    "!pip install keras\n",
    "!pip intall --upgrade keras\n",
    "!pip install ipympl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T19:52:04.505051642Z",
     "start_time": "2024-06-05T19:52:04.359994601Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import seaborn.objects as so\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from formulaic import Formula\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from time import time\n",
    "import logging\n",
    "import os\n",
    "\n",
    "# Estas dos lineas son para silenciar las advertencias de TensorFlow\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "logging.getLogger('tensorflow').setLevel(logging.ERROR)\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "from tf_regressor import train_test_split_scale_center"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c48a6ff68493b1f",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Redes Neuronales\n",
    "\n",
    "### Laboratorio de Datos, IC - FCEN - UBA - 1er. Cuatrimestre 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d040c0eba6ca5a15",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### 1. Perceptrón Simple : clasificación binaria "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797d53b60f58a291",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Armaremos una red neuronal para predecir si una persona tiene o no diabetes a partir de 8 caracteristicas:\n",
    "- Embarazos\n",
    "- Glucosa\n",
    "- Presión sanguínea\n",
    "- Grosor de la piel\n",
    "- Insulina\n",
    "- Indice de masa corporal (BMI)\n",
    "- Antecedentes familiares\n",
    "- Edad\n",
    "\n",
    "Como se trata de un problema de clasificación, la función de activación será la función sigmoidea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d742cb2aaedb22",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T21:05:01.383917661Z",
     "start_time": "2024-06-05T21:05:01.231659915Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Cargamos el dataset y descartamos las observaciones con campos faltantes\n",
    "data = pd.read_csv('diabetes.csv')\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "# Definimos las variables.\n",
    "X = data.drop('Outcome', axis=1)    # Queremos todas las columnas salvo Outcome\n",
    "y = data['Outcome']\n",
    "\n",
    "# Escalamos y centramos X, definimos conjuntos de entrenamiento y testeo\n",
    "X_train, X_test, y_train, y_test = train_test_split_scale_center(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418a7928075910ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T21:15:09.658320003Z",
     "start_time": "2024-06-05T21:15:09.509538183Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# En pro de la reproducibilidad, especificamos la semilla para keras\n",
    "keras.utils.set_random_seed(11)\n",
    "\n",
    "# Paso 1: iniciamos el modelo indicando la arquitectura de la red\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Input(shape=(8,)),             # Capa de input: indicamos que el input tiene dimension 4\n",
    "    keras.layers.Dense(1,                       # Capa de output: el output tiene dimension 1 (clasificacion binaria)\n",
    "                       activation='sigmoid')    # y su funcion de activacion es la sigmoidea.\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4af5565341e9f5f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T21:15:11.435440743Z",
     "start_time": "2024-06-05T21:15:11.423990243Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Paso 2: configuramos el optimizador: usaremos Descenso por Gradiente Estocástico con learning rate constante 0.5\n",
    "# Documentacion SGD : https://keras.io/api/optimizers/sgd/ \n",
    "optimizer = keras.optimizers.SGD(learning_rate=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d33af6cd31d6bc0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T21:15:12.424543484Z",
     "start_time": "2024-06-05T21:15:12.357762289Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Paso 3: construimos el modelo\n",
    "model.compile(\n",
    "    optimizer=optimizer,            # Optimizador a utilizar\n",
    "    loss='binary_crossentropy',     # Funcion de perdida para clasificacion binaria\n",
    "    metrics=['accuracy',            # Metricas a registrar durante el entrenamiento\n",
    "             'false_negatives']            \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42ed777432320d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T21:15:24.194765765Z",
     "start_time": "2024-06-05T21:15:13.456094403Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Paso 4: entrenamiento del modelo. \n",
    "# model.fit devuelve un objeto History que guarda la evolucion del valor de la funcion de perdida y de las metricas \n",
    "# luego de cada epoca.\n",
    "hist = model.fit(X_train.to_numpy(), y_train.to_numpy(),    # Ingresamos los datos de entrenamiento\n",
    "                 epochs=150,                                 # Especificamos la cantidad de épocas\n",
    "                 batch_size=20,                             # Especificamos el tamaño del batch\n",
    "                 validation_split=0.2,                      # 20% de datos para validación\n",
    "                 verbose=0,                                 # Opcional, para que no muestre el proceso de entrenamiento.\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec1d7598bfea241",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T21:15:24.255290741Z",
     "start_time": "2024-06-05T21:15:24.238340245Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Paso 5: calculamos el error en el conjunto de testeo\n",
    "model.evaluate(X_test.to_numpy(), y_test.to_numpy(),\n",
    "               verbose=0,\n",
    "               batch_size=len(y_test),\n",
    "               return_dict=True\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de25e3f9e1933ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T21:15:35.211204353Z",
     "start_time": "2024-06-05T21:15:35.204323012Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Armamos una funcion para graficar el error a través de las épocas\n",
    "def graficar_error(history, error_name):\n",
    "    x_arr = np.array(history.epoch)    # en el atributo epoch, history guarda una lista de epocas\n",
    "    plot = (\n",
    "        so.Plot()\n",
    "        .add(so.Line(color='blue'), x=x_arr, y=history.history[error_name], label='Entrenamiento')\n",
    "        .add(so.Line(color='orange'), x=x_arr, y=history.history[f'val_{error_name}'], label='Validacion')\n",
    "        .label(title=error_name)\n",
    "    )\n",
    "    plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8f15746a4d07d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T21:15:55.931426831Z",
     "start_time": "2024-06-05T21:15:55.595902809Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "graficar_error(hist, 'accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a481c42cd70caf9f",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Analizando los pesos, podemos interpretar qué factor es más influyente en el diagnóstico de diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f2ee87b78f81cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T21:12:55.821329917Z",
     "start_time": "2024-06-05T21:12:55.570998229Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Aqui se guardan los pesos en la primera coordenada y el bias en la segunda\n",
    "model.weights\n",
    "\n",
    "# Recuperamos los pesos:\n",
    "weights = model.weights[0].numpy().flatten()\n",
    "\n",
    "# Armamos una Serie para simplificar el análisis\n",
    "pd.Series(weights, index=X_train.columns, name='Peso en la RN')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7022857dbea647e2",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### 2. Perceptrón Simple : clasificación en más de dos categorías"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47336c8dd9947ff0",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Ahora, dadas las cuatro características de los pingüinos (peso, longitud de aleta y profundidad y longitud del pico), \n",
    "intentaremos predecir de qué especie es (Adelie, Chinstrap o Gentoo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f35d70ab4f52ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T21:48:11.673020629Z",
     "start_time": "2024-06-05T21:48:11.657058189Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Cargamos el dataset y descartamos las observaciones con campos faltantes\n",
    "penguins = sns.load_dataset('penguins')\n",
    "penguins.dropna(inplace=True)\n",
    "\n",
    "# Como en el dataset los pinguinos estan ordenados por especie, estaria bueno mezclar el DataFrame\n",
    "penguins = penguins.sample(len(penguins))\n",
    "\n",
    "# Definimos las variables.\n",
    "X = penguins[['bill_length_mm', 'flipper_length_mm', 'bill_depth_mm', 'body_mass_g']]\n",
    "# Armamos una Serie las etiquetas: 0 corresponde a Gentoo, 1 corresponde a Adelie, 2 corresponde a Chinstrap\n",
    "y = penguins['species'].apply(lambda x: 1*(x == 'Adelie') + 2*(x == 'Chinstrap'))    \n",
    "\n",
    "# Escalamos y centramos X, definimos conjuntos de entrenamiento y testeo\n",
    "X_train, X_test, y_train, y_test = train_test_split_scale_center(X, y, test_size=0.2, random_state=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35e365ed79cf36a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T21:48:17.613735924Z",
     "start_time": "2024-06-05T21:48:13.856584907Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "keras.utils.set_random_seed(11)\n",
    "\n",
    "# Paso 1: iniciamos el modelo indicando la arquitectura de la red\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Input(shape=(4,)),             # Capa de input: indicamos que el input tiene dimension 4\n",
    "    keras.layers.Dense(3,                       # Capa de output: el output tiene dimension 3 (una neurona para cada especie)\n",
    "                       activation='sigmoid')    # y su funcion de activacion es la sigmoidea.\n",
    "])\n",
    "\n",
    "# Paso 2: configuramos el optimizador\n",
    "optimizer = keras.optimizers.SGD(learning_rate=0.5)\n",
    "\n",
    "# Paso 3: construimos el modelo\n",
    "model.compile(\n",
    "    optimizer=optimizer,                        \n",
    "    loss='sparse_categorical_crossentropy',     # Funcion de perdida para clasificacion con mas de dos categorias\n",
    "    metrics=['accuracy']                        \n",
    ")\n",
    "\n",
    "# Paso 4: entrenamiento del modelo. \n",
    "hist = model.fit(X_train.to_numpy(), y_train.to_numpy(),    \n",
    "                 epochs=150,                                 \n",
    "                 batch_size=20,                             \n",
    "                 validation_split=0.2,                      \n",
    "                 verbose=0,                                 \n",
    "                 )\n",
    "\n",
    "# Paso 5: calculamos el error en el conjunto de testeo\n",
    "model.evaluate(X_test.to_numpy(), y_test.to_numpy(),\n",
    "               verbose=0,\n",
    "               batch_size=len(y_test),\n",
    "               return_dict=True\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fe16fa9c99a6ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T21:48:17.929130201Z",
     "start_time": "2024-06-05T21:48:17.620012292Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Graficamos la evolucion de la precision de la clasficiacion\n",
    "graficar_error(hist, 'accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25599f3dc9b0a13",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### 3. Perceptrón Multicapa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98db6bc8224958d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T22:29:24.144782734Z",
     "start_time": "2024-06-05T22:29:23.921652064Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('nutrition.csv')\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7395eb34-2c56-4496-a12a-411d4ac58324",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3ecfc4966388a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T22:34:50.620026530Z",
     "start_time": "2024-06-05T22:34:50.603797462Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "data.dropna(inplace=True)\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6096dbe5aaf6faf2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T22:52:36.295043322Z",
     "start_time": "2024-06-05T22:52:36.170765785Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "X = data.drop(columns=['FDC_ID', 'Item', 'Category', 'Calorias_kcal'])\n",
    "y = data['Calorias_kcal']\n",
    "\n",
    "# Escalamos y centramos X, definimos conjuntos de entrenamiento y testeo\n",
    "X_train, X_test, y_train, y_test = train_test_split_scale_center(X, y, transform_y=True, test_size=0.2, random_state=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2517a12def2fe070",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T22:53:07.921509495Z",
     "start_time": "2024-06-05T22:52:58.871540549Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "keras.utils.set_random_seed(11)\n",
    "\n",
    "# Paso 1: iniciamos el modelo indicando la arquitectura de la red\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Input(shape=(X_train.shape[1],)), \n",
    "    keras.layers.Dense(4,                       \n",
    "                       activation='sigmoid'),\n",
    "    keras.layers.Dense(1,                       \n",
    "                       activation='sigmoid')    \n",
    "])\n",
    "\n",
    "# Paso 2: configuramos el optimizador\n",
    "optimizer = keras.optimizers.SGD(learning_rate=0.5)\n",
    "\n",
    "# Paso 3: construimos el modelo\n",
    "model.compile(\n",
    "    optimizer=optimizer,                        \n",
    "    loss='mean_squared_error',                    \n",
    ")\n",
    "\n",
    "# Paso 4: entrenamiento del modelo. \n",
    "hist = model.fit(X_train.to_numpy(), y_train.to_numpy(),    \n",
    "                 epochs=100,                                 \n",
    "                 batch_size=20,                             \n",
    "                 validation_split=0.2,                      \n",
    "                 verbose=0,                                 \n",
    "                 )\n",
    "\n",
    "# Paso 5: calculamos el error en el conjunto de testeo\n",
    "model.evaluate(X_test.to_numpy(), y_test.to_numpy(),\n",
    "               verbose=0,\n",
    "               batch_size=len(y_test),\n",
    "               return_dict=True\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adec92465f1d6238",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T22:53:18.684348754Z",
     "start_time": "2024-06-05T22:53:18.340356290Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "graficar_error(hist, 'loss')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
