{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fd71cd-c23a-4837-9715-57299167f9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import seaborn.objects as so\n",
    "\n",
    "# Para clustering\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.datasets import make_circles\n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import DBSCAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089c9eab-8a35-42a8-b084-d6fa42a25299",
   "metadata": {},
   "source": [
    "**Ejercicio 1**\n",
    "\n",
    "Trabajamos con las variables \"bill_length_mm\" y \"bill_depth_mm\" de pinguinos.\n",
    "\n",
    "1. Escalar las variables por MinMax (KNN es sensible a las escalas)\n",
    "2. Para cada uno de los pinguinos 15, 151 y 313 (ver slides), numerar en un grafico los 9 pinguinos mas cercanos, ordenados de más cerca a más lejos.\n",
    "3. Clasificar cada pingüino utilizando KNN con K = 1, 3 y 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35216f48-5cc8-49a3-b06a-8e0bf2fc39d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizamos NearestNeighbors para obtener los vecinos más cercanos\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8105de1f-3905-4f52-bd28-7c12bb3a5be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminamos datos faltantes y reseteamos los índices, para no tener problemas al graficar\n",
    "penguins = sns.load_dataset(\"penguins\").dropna().reset_index(drop=True)\n",
    "\n",
    "# Normalizamos las variables \"bill_length_mm\" y \"bill_depth_mm\" por MinMax\n",
    "penguins[[\"bill_length_mm\", \"bill_depth_mm\"]] = MinMaxScaler().fit_transform(penguins[[\"bill_length_mm\", \"bill_depth_mm\"]])\n",
    "\n",
    "penguins.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997d8e68-8c5b-4085-8442-7eb020b77072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nos quedamos solo con largo y profundidad del pico\n",
    "datos = penguins[[\"bill_depth_mm\", \"bill_length_mm\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11432692-8982-431d-be73-1856d792f09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veamos primero los 9 vecinos más cercanos del pingüino 15\n",
    "K = 9\n",
    "ind = 313\n",
    "neighbors = NearestNeighbors(n_neighbors=???)  # Esta función nos devuelve los más cercanos incluyendo a si mismo, por eso tomamos 10.\n",
    "neighbors.fit(datos)  # En el ajuste solamente almacenamos los datos\n",
    "\n",
    "# Ahora podemos buscar los vecinos más cercanos a un punto cualquiera o un conjunto de puntos.\n",
    "# Tenemos que pasarle un DataFrame\n",
    "distances, indices = neighbors.kneighbors(???)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfcaa84-d760-48fe-aa8d-2a7130881091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nos devuelve un vector de distancias (opcional)\n",
    "distances.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a338f7f4-c98a-4cc7-b85e-744bd5dbade6",
   "metadata": {},
   "source": [
    "Vemos que las distancias están ordenadas de menor a mayor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdd9a9e-31fa-4dbc-8855-d6a812dbfbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y un vector de índices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cc6e09-0446-4332-9aff-cd754611b9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cda53fa-53c3-464d-aab9-327a69db2332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos\n",
    "(\n",
    "    so.Plot(data = penguins.iloc[indices.flatten()], x = \"bill_length_mm\", y = \"bill_depth_mm\",  text = np.arange(K+1).astype(str))\n",
    "    .add(so.Text(valign = \"bottom\"))\n",
    "    .add(so.Dot(), color = \"species\")\n",
    "    .add(so.Dot(color = \"red\"), data = penguins.iloc[[ind]], x = \"bill_length_mm\", y = \"bill_depth_mm\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80f86d4-9760-41e1-9cb8-3bfdb9ccfda2",
   "metadata": {},
   "source": [
    "**Ejercicio 2**\n",
    "\n",
    "1. Implementar una función que reciba un DataFrame (que tenga solo las variables numéricas a utilizar para medir distancias), un vector de categorías (indexado igual que el DataFrame), un índice y un valor de K y devuelva la predicción por K-means para el dato indicado. Importante: debemos ignorar al propio dato en la votación.\n",
    "2. Aplicar la función a los datos de pingüinos.\n",
    "\n",
    "**Sugerencia:** para elegir la categoría más votada podemos calcular la moda. El paquete statistics provee el comando `mode`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b260eaa-22cf-471b-886a-dcb1dff4cc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos el comando mode\n",
    "import statistics\n",
    "from statistics import mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b41f28-38dd-46e8-9223-926b63cac59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Item 1\n",
    "\n",
    "# Antes de hacer la función lo calculamos para un ejemplo.\n",
    "K = 9\n",
    "ind = 151\n",
    "datos = penguins[[\"bill_depth_mm\", \"bill_length_mm\"]]\n",
    "categorias = penguins[\"species\"]\n",
    "\n",
    "neighbors = NearestNeighbors(n_neighbors= K)  # Vamos a eliminar al propio pinguino de los datos, por eso tomamos K.\n",
    "neighbors.fit(???)\n",
    "\n",
    "distances, indices = neighbors.kneighbors(???)\n",
    "votos = categorias[indices.flatten()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca23882b-1746-4ee5-adfc-c94176c5f0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "votos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8dbf24-bc1f-4e3a-b7a2-b62dce1c85e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# El mas votado\n",
    "???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07088beb-ef0b-4b0d-87b0-e267a78d01e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Juntamos todo en una función\n",
    "def mas_votado(datos, categorias, ind, K):\n",
    "    neighbors = NearestNeighbors(n_neighbors= K)  # Vamos a eliminar al propio pinguino de los datos, por eso tomamos K.\n",
    "    neighbors.fit(datos.drop([ind]))\n",
    "\n",
    "    distances, indices = neighbors.kneighbors(datos.iloc[[ind]])\n",
    "    votos = categorias[indices.flatten()]\n",
    "\n",
    "    return(mode(votos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef6d8ca-b17a-48f6-b24c-16ee7b97a1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Item 2 - Aplicamos la función a los datos de pingüinos\n",
    "datos = penguins[[\"bill_depth_mm\", \"bill_length_mm\"]]\n",
    "categorias = penguins[\"species\"]\n",
    "mas_votado(datos, categorias, 313, 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ca3fa3-f946-448a-9d3a-1b5b411871ae",
   "metadata": {},
   "source": [
    "**Ejercicio 3**\n",
    "1. Implementar una función que reciba un DataFrame, un vector de categorías y un valor de K y calcule las predicciones para todos los datos y nos devuelva el porcentaje de aciertos.\n",
    "2. Aplicar la función a los datos de pingüinos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23d05b1-b1c2-43cc-a0c3-a73259bd3c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Item 1\n",
    "def knn_leave_one_out(datos, categorias, K):\n",
    "    correctos = 0\n",
    "    total = len(datos)\n",
    "    ???\n",
    "    \n",
    "    return(correctos / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036f689d-496f-4f48-b4c6-86a6f66f7217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Item 2 - Aplicamos la función a los datos de pingüinos\n",
    "datos = penguins[[\"bill_depth_mm\", \"bill_length_mm\"]]\n",
    "categorias = penguins[\"species\"]\n",
    "knn_leave_one_out(datos, categorias, 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71890163-aedd-4840-8996-69589dc626bc",
   "metadata": {},
   "source": [
    "**Ejercicio 4**\n",
    "Utilizando las funciones de los ejercicios anteriores, calcular el valor de $K$ (impar) óptimo para predecir la especie de un pingüino."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e773f1e1-10c5-4963-8041-2d56589926f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "???"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55854f16-12fd-4681-8f60-de1951627500",
   "metadata": {},
   "source": [
    "## Ejemplo: detección temprana de diabetes\n",
    "\n",
    "A partir de distintos datos de pacientes queremos detectar tempranamente si ese paciente va a sufrir diabetes.\n",
    "\n",
    "1. Leer los datos del archivo \"diabetes.csv\".\n",
    "2. Separar la columna \"Outcome\" como variable respuesta y el resto como variables explicativas.\n",
    "3. Escalar las variables explicativas por MinMax\n",
    "4. Partir la muestra en un 80% para entrenamiento y un 20% para testeo.\n",
    "5. Se quiere predecir la variable respuesta por KNN. Calcular el valor óptimo de $K$ optimizando el porcentaje de aciertos en testeo.\n",
    "7. Para el valor hallado, calcular la matriz de confusión en testeo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f3329b-e53a-49e5-9dda-b0a345ae0b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizamos estos paquetes\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184fa2ed-9f67-4a68-bdd6-878fa7402f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "datos = pd.read_csv(\"../Datos/diabetes.csv\")\n",
    "datos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3701b08-055f-4d44-b6d0-cab50e66b41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Separamos la variable respuesta\n",
    "X = datos.drop(\"Outcome\",axis=1)\n",
    "y = datos[\"Outcome\"]\n",
    "\n",
    "# 3. Escalamos X\n",
    "X = MinMaxScaler().set_output(transform=\"pandas\").fit_transform(X)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ab894b-d209-4f34-a53c-4fbbc0599ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos en entrenamiento y validación\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aeb6590-de65-47cb-bd57-f5e4a708e4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbor = KNeighborsClassifier(n_neighbors=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d545912e-2fa2-495b-97fd-0ba256b4a1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamos utilizando X_train\n",
    "neighbor.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e28335-115e-4239-8eee-e10e8d64ee08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos utilizando X_test\n",
    "y_pred = neighbor.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59cfe063-b62c-4194-83a7-90f7fb311617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculamos la precisión con accuracy_score\n",
    "print(accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa489cc-7493-4fe9-8d38-51ec574c1cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repetimos todo para varios valores de K\n",
    "for K in range(1,30,2):\n",
    "    neighbor = KNeighborsClassifier(n_neighbors=K)\n",
    "    neighbor.fit(X_train,y_train)\n",
    "    y_pred = neighbor.predict(X_test)\n",
    "    print(K, accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebe409f-d366-4ea3-b1ab-d6bb6e93a136",
   "metadata": {},
   "source": [
    "**Matriz de confusión**\n",
    "La matriz de confusión $C$ guarda en la coordenada $C_{ij}$ la cantidad de observaciones en el grupo $i$ que fueron clasificadas en el grupo $j$.\n",
    "\n",
    "Si la variable es binaria:\n",
    "- $C_{00}$ son los casos negativos clasificados correctamente.\n",
    "- $C_{01}$ son los casos negativos  clasificados como positivos (falsos positivos).\n",
    "- $C_{10}$ son los casos positivos  clasificados como negativos (falsos negativos).\n",
    "- $C_{11}$ son los casos positivos clasificados correctamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a197cfb1-0fd6-4a46-8e85-3dfdda7793b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 21\n",
    "neighbor = KNeighborsClassifier(n_neighbors=K)\n",
    "neighbor.fit(X_train,y_train)\n",
    "y_pred = neighbor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8829089f-be16-428c-a04a-1a20f3715c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = confusion_matrix(y_test,y_pred)\n",
    "display(C)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29290fb7-8a01-4e47-a535-e7260e411254",
   "metadata": {},
   "source": [
    "**Ejercicio:** Calcular el coeficiente $C_{01}$ a mano."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2790e51-ecce-4fd1-a1e7-5ce8081d611c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum((y_pred==1) & (y_test==0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31acc17e-27aa-4588-9866-e916d63c738d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
